{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Quantum-Enhanced Language Model Fine-Tuning with Merlin\n",
    "\n",
    "This notebook demonstrates how to fine-tune language models using quantum photonic circuits as classification heads. We compare classical approaches (Logistic Regression, SVM, MLP) with quantum photonic classifiers implemented using the Merlin framework.\n",
    "\n",
    "\n",
    " ## 1. Setup and Imports\n",
    "\n",
    " First, we'll import all necessary libraries and set up our environment. This includes:\n",
    " - PyTorch for neural network operations\n",
    " - SetFit for few-shot learning\n",
    " - Merlin for quantum photonic circuit simulation\n",
    " - Standard ML libraries for evaluation and data handling\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import merlin as ML  # Using our Merlin framework\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset\n",
    "from setfit import SetFitModel, sample_dataset\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:10:12.492706100Z",
     "start_time": "2025-06-05T14:10:00.468677700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 2. Model Wrapper for Sentence Transformers\n",
    "\n",
    " The `ModelWrapper` class provides a unified interface for handling tokenization and forward passes with sentence transformer models. This abstraction allows us to work with different model architectures seamlessly.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def tokenize(self, texts):\n",
    "        \"\"\"\n",
    "        Delegates tokenization to the underlying model.\n",
    "\n",
    "        Args:\n",
    "            texts (List[str]): List of text strings to tokenize\n",
    "\n",
    "        Returns:\n",
    "            Dict or Tensor: Tokenized inputs in the format expected by the model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try to use the tokenize method of the underlying model\n",
    "            return self.model.tokenize(texts)\n",
    "        except AttributeError:\n",
    "            # If the model doesn't have a tokenize method, try alternative approaches\n",
    "            if hasattr(self.model, 'tokenizer'):\n",
    "                return self.model.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "            elif hasattr(self.model, '_first_module') and hasattr(self.model._first_module, 'tokenizer'):\n",
    "                return self.model._first_module.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Unable to tokenize texts with this model. Please provide a model that has a tokenize or tokenizer method.\")\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Process inputs through the model to get embeddings.\n",
    "\n",
    "        Args:\n",
    "            inputs: Can be raw text strings or pre-tokenized inputs\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The sentence embeddings\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Handle different input formats\n",
    "            if isinstance(inputs, dict) and all(isinstance(v, torch.Tensor) for v in inputs.values()):\n",
    "                outputs = self.model(inputs)\n",
    "            elif isinstance(inputs, list) and all(isinstance(t, str) for t in inputs):\n",
    "                tokenized = self.tokenize(inputs)\n",
    "                device = next(self.model.parameters()).device\n",
    "                tokenized = {k: v.to(device) for k, v in tokenized.items()}\n",
    "                outputs = self.model(tokenized)\n",
    "            else:\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "            # Extract embeddings from various output formats\n",
    "            if isinstance(outputs, dict) and \"sentence_embedding\" in outputs:\n",
    "                return outputs[\"sentence_embedding\"]\n",
    "            elif isinstance(outputs, dict) and \"pooler_output\" in outputs:\n",
    "                return outputs[\"pooler_output\"]\n",
    "            elif isinstance(outputs, tuple) and len(outputs) > 0:\n",
    "                return outputs[0]\n",
    "            else:\n",
    "                return outputs\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error during forward pass: {str(e)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:10:12.511038700Z",
     "start_time": "2025-06-05T14:10:12.492706100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 3. Evaluation Function\n",
    "\n",
    " This function evaluates a SetFit model on given texts and labels, processing data in batches for efficiency.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def evaluate(model, texts, labels):\n",
    "    \"\"\"\n",
    "    Evaluate SetFit model on given texts and labels.\n",
    "\n",
    "    Args:\n",
    "        model: SetFit model with a trained classification head\n",
    "        texts: List of text strings to classify\n",
    "        labels: True labels for evaluation\n",
    "\n",
    "    Returns:\n",
    "        tuple: (accuracy, predictions)\n",
    "    \"\"\"\n",
    "    batch_size = 16\n",
    "    num_samples = len(texts)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "\n",
    "            batch_texts = texts[start_idx:end_idx]\n",
    "\n",
    "            # Get embeddings\n",
    "            batch_embeddings = model.model_body.encode(batch_texts, convert_to_tensor=True)\n",
    "            batch_embeddings_cpu = batch_embeddings.detach().cpu().numpy()\n",
    "\n",
    "            all_embeddings.extend(batch_embeddings_cpu)\n",
    "\n",
    "    # Use the classification head to predict\n",
    "    predictions = model.model_head.predict(np.array(all_embeddings))\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return accuracy, predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:10:12.550888100Z",
     "start_time": "2025-06-05T14:10:12.505749300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 4. Classical Classification Heads\n",
    "\n",
    " ### 4.1 MLP Classifier\n",
    "\n",
    " We implement a 3-layer Multi-Layer Perceptron (MLP) as one of our classical baselines. The architecture includes:\n",
    " - Input layer matching the embedding dimension (768 for most transformers)\n",
    " - Two hidden layers with ReLU activation and dropout\n",
    " - Output layer for classification\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    \"\"\"3-layer MLP classifier with dropout regularization\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim=100, num_classes=2):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MLPClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Scikit-learn compatible wrapper for the MLP classifier\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=768, hidden_dim=100, num_classes=2,\n",
    "                 lr=0.001, epochs=100, batch_size=32, device=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the MLP classifier\"\"\"\n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # Store unique classes\n",
    "        self.classes_ = np.unique(y)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # Initialize the model\n",
    "        self.model = MLPClassifier(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            num_classes=len(self.classes_)\n",
    "        ).to(self.device)\n",
    "\n",
    "        print(f\"Number of parameters in MLP head: {sum([p.numel() for p in self.model.parameters()])}\")\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            # Mini-batch training\n",
    "            indices = torch.randperm(len(X))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i in range(0, len(X), self.batch_size):\n",
    "                batch_indices = indices[i:i + self.batch_size]\n",
    "                batch_X = X[batch_indices]\n",
    "                batch_y = y_tensor[batch_indices]\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            # Print progress\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                avg_loss = total_loss / (len(X) // self.batch_size + 1)\n",
    "                print(f'Epoch [{epoch + 1}/{self.epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes for samples\"\"\"\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            return self.classes_[predicted.cpu().numpy()]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities\"\"\"\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            return probabilities\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:10:12.558048100Z",
     "start_time": "2025-06-05T14:10:12.522560100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 4.2 Helper Function to Replace SetFit Head\n",
    "\n",
    " This function allows us to easily swap the default classification head with our custom MLP.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def replace_setfit_head_with_mlp(model, input_dim=768, hidden_dim=100, num_classes=2, epochs=100):\n",
    "    \"\"\"Replace the classification head of a SetFitModel with an MLP.\"\"\"\n",
    "    # Get the device the model is on\n",
    "    device = next(model.model_body.parameters()).device\n",
    "\n",
    "    # Create new MLP head\n",
    "    mlp_head = MLPClassifierWrapper(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        epochs=epochs,\n",
    "        lr=0.001,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Replace the model head\n",
    "    model.model_head = mlp_head\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:10:12.558048100Z",
     "start_time": "2025-06-05T14:10:12.535142400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 5. Quantum Classification Head\n",
    "\n",
    " ### 5.1 Quantum Photonic Classifier\n",
    "\n",
    " The quantum classifier uses a photonic interferometer implemented with the Merlin framework. The architecture consists of:\n",
    "\n",
    " 1. **Downscaling layer**: Reduces the embedding dimension to match quantum circuit requirements\n",
    " 2. **Quantum photonic circuit**: Processes the downscaled features through quantum interference\n",
    " 3. **Output layer**: Maps quantum measurements to class predictions\n",
    "\n",
    " The quantum circuit parameters:\n",
    " - **Modes**: Number of optical modes in the interferometer\n",
    " - **Photons**: Number of photons in the input state\n",
    " - **Input state**: Distribution of photons across modes\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class QuantumClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=100, modes=10, num_classes=2, input_state=None):\n",
    "        super(QuantumClassifier, self).__init__()\n",
    "\n",
    "        # This layer downscales the inputs to fit in the QLayer\n",
    "        self.downscaling_layer = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Building the QLayer with Merlin\n",
    "        experiment = ML.PhotonicBackend(\n",
    "            circuit_type=ML.CircuitType.SERIES,\n",
    "            n_modes=modes,\n",
    "            n_photons=sum(input_state) if input_state else modes // 2,\n",
    "            state_pattern=ML.StatePattern.PERIODIC\n",
    "        )\n",
    "\n",
    "        # Default input state\n",
    "        if input_state is None:\n",
    "            input_state = [(i + 1) % 2 for i in range(modes)]\n",
    "\n",
    "        photons_count = sum(input_state)\n",
    "        # PNR (Photon Number Resolving) output size\n",
    "        #output_size_slos = math.comb(modes + photons_count - 1, photons_count)\n",
    "\n",
    "        # Create ansatz for the quantum layer\n",
    "        ansatz = ML.AnsatzFactory.create(\n",
    "            PhotonicBackend=experiment,\n",
    "            input_size=hidden_dim,\n",
    "           # output_size=output_size_slos,\n",
    "            output_mapping_strategy=ML.OutputMappingStrategy.NONE\n",
    "        )\n",
    "\n",
    "        # Build the QLayer using Merlin\n",
    "        self.q_circuit = ML.QuantumLayer(input_size=hidden_dim, ansatz=ansatz)\n",
    "\n",
    "        # Linear output layer as in the original paper\n",
    "        self.output_layer = nn.Linear(self.q_circuit.output_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the quantum-classical hybrid\n",
    "        x = self.downscaling_layer(x)\n",
    "        x = torch.sigmoid(x)  # Normalize for quantum layer\n",
    "        x = self.q_circuit(x)\n",
    "        return self.output_layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:39.071475Z",
     "start_time": "2025-06-05T14:34:39.049294400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    " ### 5.2 Quantum Layer Training Wrapper\n",
    "\n",
    " This wrapper provides scikit-learn compatible training for the quantum classifier, including proper initialization, training loops, and prediction methods.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class QLayerTraining(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dim=768, hidden_dim=100, modes=10, num_classes=2,\n",
    "                 dropout_rate=0.2, lr=0.001, weight_decay=1e-5,\n",
    "                 epochs=100, batch_size=32, device=None, input_state=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.modes = modes\n",
    "        self.input_state = input_state\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Initialize model\n",
    "        self.model = None\n",
    "        self.classes_ = None\n",
    "        self.is_fitted_ = False\n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': []\n",
    "        }\n",
    "\n",
    "    def _initialize_model(self):\n",
    "        \"\"\"Initialize or re-initialize the model.\"\"\"\n",
    "        self.model = QuantumClassifier(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            modes=self.modes,\n",
    "            num_classes=len(self.classes_),\n",
    "            input_state=self.input_state,\n",
    "        ).to(self.device)\n",
    "\n",
    "        print(f\"Number of parameters in Quantum head: {sum([p.numel() for p in self.model.parameters()])}\")\n",
    "\n",
    "    def _train_epoch(self, train_loader, criterion, optimizer):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = self.model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(train_loader)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the QLayer with a manual training loop.\"\"\"\n",
    "        # Store classes\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "        # Initialize model\n",
    "        self._initialize_model()\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.epochs):\n",
    "            # Train for one epoch\n",
    "            train_loss = self._train_epoch(train_loader, criterion, optimizer)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{self.epochs}, Train Loss: {train_loss:.4f}')\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for samples in X.\"\"\"\n",
    "        self._check_is_fitted()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        return self.classes_[predicted.cpu().numpy()]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for samples in X.\"\"\"\n",
    "        self._check_is_fitted()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def _check_is_fitted(self):\n",
    "        \"\"\"Check if model is fitted.\"\"\"\n",
    "        if not self.is_fitted_ or self.model is None:\n",
    "            raise ValueError(\"This model has not been fitted yet. Call 'fit' before using this method.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:39:54.442383600Z",
     "start_time": "2025-06-05T14:39:54.425864300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 5.3 Helper Function for Quantum SetFit Models\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def create_setfit_with_q_layer(model, input_dim=768, hidden_dim=100, modes=10,\n",
    "                              num_classes=2, epochs=100, input_state=None):\n",
    "    \"\"\"\n",
    "    Replace the classification head of a SetFit model with a quantum layer.\n",
    "\n",
    "    Args:\n",
    "        model: SetFit model to modify\n",
    "        input_dim: Dimension of input embeddings\n",
    "        hidden_dim: Dimension after downscaling\n",
    "        modes: Number of modes in the quantum circuit\n",
    "        num_classes: Number of output classes\n",
    "        epochs: Training epochs for the quantum head\n",
    "        input_state: Photon distribution across modes\n",
    "\n",
    "    Returns:\n",
    "        Modified SetFit model with quantum classification head\n",
    "    \"\"\"\n",
    "    # Replace model head with QLayer\n",
    "    model.model_head = QLayerTraining(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        modes=modes,\n",
    "        num_classes=num_classes,\n",
    "        epochs=epochs,\n",
    "        input_state=input_state\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:41.852615300Z",
     "start_time": "2025-06-05T14:34:41.807099400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 6. Utility Functions\n",
    "\n",
    " ### 6.1 Results Storage\n",
    "\n",
    " Function to save experimental results in JSON format for later analysis.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def save_experiment_results(results, filename='ft-qllm_exp.json'):\n",
    "    \"\"\"\n",
    "    Append experiment results to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        results (dict): Dictionary containing experiment results\n",
    "        filename (str): Path to the JSON file to store results\n",
    "    \"\"\"\n",
    "    filename = os.path.join(\"./results\", filename)\n",
    "\n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "\n",
    "    # Check if file exists and load existing data\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                all_results = json.load(file)\n",
    "        except json.JSONDecodeError:\n",
    "            all_results = []\n",
    "    else:\n",
    "        all_results = []\n",
    "\n",
    "    # Append new results\n",
    "    all_results.append(results)\n",
    "\n",
    "    # Write updated data back to file\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(all_results, file, indent=4)\n",
    "\n",
    "    print(f\"Results saved. Total experiments: {len(all_results)}\")\n",
    "    return len(all_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:43.570450600Z",
     "start_time": "2025-06-05T14:34:43.010482200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 6.2 Contrastive Loss Implementation\n",
    "\n",
    " Simplified supervised contrastive loss for fine-tuning the sentence transformer body. In production, you would implement the full contrastive loss formula.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"Supervised Contrastive Learning Loss (simplified implementation)\"\"\"\n",
    "\n",
    "    def __init__(self, model, temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        # Simplified implementation - in practice you'd want the full contrastive loss\n",
    "        # For now, just return a dummy loss to make the training loop work\n",
    "        embeddings = self.model(features[0])\n",
    "        # This is a placeholder - implement proper contrastive loss if needed\n",
    "        return torch.tensor(0.5, requires_grad=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:44.629764900Z",
     "start_time": "2025-06-05T14:34:44.188949Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 7. Main Training Pipeline\n",
    "\n",
    " Now we'll set up the complete training pipeline that:\n",
    " 1. Loads the SST-2 sentiment analysis dataset\n",
    " 2. Fine-tunes the sentence transformer with contrastive learning\n",
    " 3. Trains multiple classification heads (classical and quantum)\n",
    " 4. Evaluates and compares all approaches\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "- Samples per class: 8\n",
      "- Body training epochs: 20\n",
      "- Head training epochs: 200\n",
      "- Learning rate: 1e-05\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_PER_CLASS = 8  # Few-shot setting\n",
    "BODY_EPOCHS = 20      # Epochs for sentence transformer fine-tuning\n",
    "HEAD_EPOCHS = 200     # Epochs for classification head training\n",
    "LEARNING_RATE = 1e-5  # Learning rate for body fine-tuning\n",
    "BATCH_SIZE = 16       # Batch size for evaluation\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- Samples per class: {SAMPLES_PER_CLASS}\")\n",
    "print(f\"- Body training epochs: {BODY_EPOCHS}\")\n",
    "print(f\"- Head training epochs: {HEAD_EPOCHS}\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:45.553117600Z",
     "start_time": "2025-06-05T14:34:45.541776400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 7.1 Load Dataset\n",
    "\n",
    " We use the Stanford Sentiment Treebank (SST-2) dataset for binary sentiment classification. In the few-shot setting, we sample only a small number of examples per class for training.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset with 8 samples per class...\n",
      "Dataset sizes:\n",
      "- Training: 16 samples\n",
      "- Validation: 250 samples\n",
      "- Test: 622 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading dataset with {SAMPLES_PER_CLASS} samples per class...\")\n",
    "dataset = load_dataset(\"sst2\")\n",
    "\n",
    "# Simulate few-shot regime by sampling examples per class\n",
    "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"label\", num_samples=SAMPLES_PER_CLASS)\n",
    "eval_dataset = dataset[\"validation\"].select(range(250))\n",
    "test_dataset = dataset[\"validation\"].select(range(250, len(dataset[\"validation\"])))\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = [example[\"sentence\"] for example in train_dataset]\n",
    "features = [texts]\n",
    "labels = torch.tensor([example[\"label\"] for example in train_dataset])\n",
    "\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"- Training: {len(train_dataset)} samples\")\n",
    "print(f\"- Validation: {len(eval_dataset)} samples\")\n",
    "print(f\"- Test: {len(test_dataset)} samples\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:53.890315300Z",
     "start_time": "2025-06-05T14:34:46.753917600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 7.2 Initialize Base Model\n",
    "\n",
    " We use a pre-trained sentence transformer as our base model. The SetFit framework provides an efficient way to perform few-shot learning.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading pre-trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: SentenceTransformer\n",
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading pre-trained model...\")\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "sentence_transformer = model.model_body\n",
    "classification_head = model.model_head\n",
    "\n",
    "print(f\"Model loaded: {type(sentence_transformer).__name__}\")\n",
    "print(f\"Embedding dimension: 768\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:56.379567100Z",
     "start_time": "2025-06-05T14:34:53.890315300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 7.3 Fine-tune Sentence Transformer Body\n",
    "\n",
    " We fine-tune the sentence transformer using contrastive learning to better adapt it to our specific task.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model body with contrastive learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrastive Learning:  25%|██▌       | 5/20 [00:09<00:30,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5/20, Loss: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrastive Learning:  50%|█████     | 10/20 [00:15<00:12,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10/20, Loss: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrastive Learning:  75%|███████▌  | 15/20 [00:20<00:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15/20, Loss: 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrastive Learning: 100%|██████████| 20/20 [00:25<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/20, Loss: 0.500000\n",
      "Model body fine-tuning completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining model body with contrastive learning...\")\n",
    "model_wrapped = ModelWrapper(sentence_transformer)\n",
    "criterion = SupConLoss(model=model_wrapped)\n",
    "\n",
    "# Enable gradients for fine-tuning\n",
    "for param in sentence_transformer.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model_wrapped.parameters(), lr=LEARNING_RATE)\n",
    "model_wrapped.train()\n",
    "\n",
    "# Training loop\n",
    "for iteration in tqdm(range(BODY_EPOCHS), desc=\"Contrastive Learning\"):\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(features, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (iteration + 1) % 5 == 0:\n",
    "        print(f\"Iteration {iteration + 1}/{BODY_EPOCHS}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "print(\"Model body fine-tuning completed!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:35:22.332644600Z",
     "start_time": "2025-06-05T14:34:56.379567100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    " ### 7.4 Generate Embeddings\n",
    "\n",
    " After fine-tuning, we generate embeddings for all training samples. These embeddings will be used to train the various classification heads.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (16, 768)\n",
      "Labels shape: (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for training data...\")\n",
    "sentence_transformer.eval()\n",
    "train_embeddings = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_batches = (len(train_dataset[\"sentence\"]) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Encoding\"):\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = min(start_idx + BATCH_SIZE, len(train_dataset[\"sentence\"]))\n",
    "\n",
    "        batch_texts = train_dataset[\"sentence\"][start_idx:end_idx]\n",
    "        batch_labels = train_dataset[\"label\"][start_idx:end_idx]\n",
    "\n",
    "        batch_embeddings = sentence_transformer.encode(batch_texts, convert_to_tensor=True)\n",
    "        batch_embeddings_cpu = batch_embeddings.detach().cpu().numpy()\n",
    "\n",
    "        for emb, lbl in zip(batch_embeddings_cpu, batch_labels):\n",
    "            train_embeddings.append(emb)\n",
    "            train_labels.append(lbl)\n",
    "\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(f\"Embeddings shape: {train_embeddings.shape}\")\n",
    "print(f\"Labels shape: {train_labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:35:23.104285200Z",
     "start_time": "2025-06-05T14:35:22.336638400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 8. Train and Evaluate Classification Heads\n",
    "\n",
    " Now we'll train different classification heads and compare their performance:\n",
    " 1. **Logistic Regression**: Simple linear classifier (baseline)\n",
    " 2. **SVM**: Support Vector Machine with linear kernel\n",
    " 3. **MLP**: Multi-layer perceptron\n",
    " 4. **Quantum Layers**: Multiple configurations with different numbers of modes and photons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classification heads for 2-class classification...\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(train_dataset[\"label\"]))\n",
    "results = {\n",
    "    \"training_samples\": SAMPLES_PER_CLASS,\n",
    "    \"epochs\": BODY_EPOCHS,\n",
    "    \"lr\": LEARNING_RATE\n",
    "}\n",
    "\n",
    "print(f\"\\nTraining classification heads for {num_classes}-class classification...\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:35:23.112530200Z",
     "start_time": "2025-06-05T14:35:23.095597400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 8.1 Logistic Regression Head\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Training Logistic Regression head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Val: 0.7680, Test: 0.7235\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Training Logistic Regression head...\")\n",
    "# Reset to default logistic regression head\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "model.model_body = sentence_transformer  # Use our fine-tuned body\n",
    "\n",
    "# Train\n",
    "model.model_head.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "lg_val_accuracy, _ = evaluate(model, eval_dataset[\"sentence\"], eval_dataset[\"label\"])\n",
    "lg_test_accuracy, _ = evaluate(model, test_dataset[\"sentence\"], test_dataset[\"label\"])\n",
    "\n",
    "print(f\"Logistic Regression - Val: {lg_val_accuracy:.4f}, Test: {lg_test_accuracy:.4f}\")\n",
    "results[\"LogisticRegression\"] = [lg_val_accuracy, lg_test_accuracy]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:36:23.594206400Z",
     "start_time": "2025-06-05T14:35:23.114172700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 8.2 SVM Head\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Training SVM head...\n",
      "SVM - Val: 0.7600, Test: 0.7395\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Training SVM head...\")\n",
    "# Replace head with SVM\n",
    "model.model_head = SVC(C=1.0, kernel='linear', gamma='scale', probability=True)\n",
    "model.model_head.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "svc_val_accuracy, _ = evaluate(model, eval_dataset[\"sentence\"], eval_dataset[\"label\"])\n",
    "svc_test_accuracy, _ = evaluate(model, test_dataset[\"sentence\"], test_dataset[\"label\"])\n",
    "\n",
    "print(f\"SVM - Val: {svc_val_accuracy:.4f}, Test: {svc_test_accuracy:.4f}\")\n",
    "results[\"SVC\"] = [svc_val_accuracy, svc_test_accuracy]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:37:16.608070600Z",
     "start_time": "2025-06-05T14:36:23.594206400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### 8.3 MLP Head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Training MLP head...\n",
      "Number of parameters in MLP head: 82052\n",
      "Epoch [10/200], Loss: 0.5600\n",
      "Epoch [20/200], Loss: 0.2970\n",
      "Epoch [30/200], Loss: 0.0889\n",
      "Epoch [40/200], Loss: 0.0123\n",
      "Epoch [50/200], Loss: 0.0021\n",
      "Epoch [60/200], Loss: 0.0016\n",
      "Epoch [70/200], Loss: 0.0007\n",
      "Epoch [80/200], Loss: 0.0005\n",
      "Epoch [90/200], Loss: 0.0003\n",
      "Epoch [100/200], Loss: 0.0005\n",
      "Epoch [110/200], Loss: 0.0004\n",
      "Epoch [120/200], Loss: 0.0003\n",
      "Epoch [130/200], Loss: 0.0002\n",
      "Epoch [140/200], Loss: 0.0003\n",
      "Epoch [150/200], Loss: 0.0002\n",
      "Epoch [160/200], Loss: 0.0001\n",
      "Epoch [170/200], Loss: 0.0001\n",
      "Epoch [180/200], Loss: 0.0001\n",
      "Epoch [190/200], Loss: 0.0002\n",
      "Epoch [200/200], Loss: 0.0001\n",
      "MLP - Val: 0.8120, Test: 0.7797\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Training MLP head...\")\n",
    "# Replace head with MLP\n",
    "model = replace_setfit_head_with_mlp(\n",
    "    model,\n",
    "    input_dim=768,\n",
    "    hidden_dim=100,\n",
    "    num_classes=num_classes,\n",
    "    epochs=HEAD_EPOCHS\n",
    ")\n",
    "model.model_head.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "mlp_val_accuracy, _ = evaluate(model, eval_dataset[\"sentence\"], eval_dataset[\"label\"])\n",
    "mlp_test_accuracy, _ = evaluate(model, test_dataset[\"sentence\"], test_dataset[\"label\"])\n",
    "\n",
    "print(f\"MLP - Val: {mlp_val_accuracy:.4f}, Test: {mlp_test_accuracy:.4f}\")\n",
    "results[\"MLP\"] = [mlp_val_accuracy, mlp_test_accuracy]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:38:04.880276900Z",
     "start_time": "2025-06-05T14:37:16.608070600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    " ### 8.4 Quantum Layer Heads\n",
    "\n",
    " We test multiple quantum configurations with varying numbers of modes and photons. Each configuration represents a different quantum circuit complexity and expressivity.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Training Quantum Layer heads...\n",
      "\n",
      "   Training Quantum Head: 2 modes, 1 photons\n",
      "   Input state: [1, 0]\n",
      "Number of parameters in Quantum head: 76914\n",
      "Epoch 50/200, Train Loss: 0.7770\n",
      "Epoch 100/200, Train Loss: 0.6836\n",
      "Epoch 150/200, Train Loss: 0.6058\n",
      "Epoch 200/200, Train Loss: 0.5386\n",
      "   Quantum 2-1 - Val: 0.5160, Test: 0.5064\n",
      "\n",
      "   Training Quantum Head: 4 modes, 1 photons\n",
      "   Input state: [1, 0, 0, 0]\n",
      "Number of parameters in Quantum head: 76942\n",
      "Epoch 50/200, Train Loss: 0.6405\n",
      "Epoch 100/200, Train Loss: 0.5644\n",
      "Epoch 150/200, Train Loss: 0.5003\n",
      "Epoch 200/200, Train Loss: 0.4458\n",
      "   Quantum 4-1 - Val: 0.7880, Test: 0.7685\n",
      "\n",
      "   Training Quantum Head: 4 modes, 2 photons\n",
      "   Input state: [1, 0, 1, 0]\n",
      "Number of parameters in Quantum head: 76946\n",
      "Epoch 50/200, Train Loss: 0.6423\n",
      "Epoch 100/200, Train Loss: 0.5621\n",
      "Epoch 150/200, Train Loss: 0.4861\n",
      "Epoch 200/200, Train Loss: 0.4328\n",
      "   Quantum 4-2 - Val: 0.7920, Test: 0.7588\n",
      "\n",
      "   Training Quantum Head: 6 modes, 1 photons\n",
      "   Input state: [1, 0, 0, 0, 0, 0]\n",
      "Number of parameters in Quantum head: 76986\n",
      "Epoch 50/200, Train Loss: 0.6378\n",
      "Epoch 100/200, Train Loss: 0.5383\n",
      "Epoch 150/200, Train Loss: 0.4465\n",
      "Epoch 200/200, Train Loss: 0.3754\n",
      "   Quantum 6-1 - Val: 0.7680, Test: 0.7010\n",
      "\n",
      "   Training Quantum Head: 6 modes, 2 photons\n",
      "   Input state: [1, 0, 1, 0, 0, 0]\n",
      "Number of parameters in Quantum head: 77004\n",
      "Epoch 50/200, Train Loss: 0.6290\n",
      "Epoch 100/200, Train Loss: 0.5511\n",
      "Epoch 150/200, Train Loss: 0.4831\n",
      "Epoch 200/200, Train Loss: 0.4275\n",
      "   Quantum 6-2 - Val: 0.8040, Test: 0.7653\n",
      "\n",
      "   Training Quantum Head: 6 modes, 3 photons\n",
      "   Input state: [1, 0, 1, 0, 1, 0]\n",
      "Number of parameters in Quantum head: 77014\n",
      "Epoch 50/200, Train Loss: 0.6118\n",
      "Epoch 100/200, Train Loss: 0.5410\n",
      "Epoch 150/200, Train Loss: 0.4739\n",
      "Epoch 200/200, Train Loss: 0.4005\n",
      "   Quantum 6-3 - Val: 0.7840, Test: 0.7669\n",
      "\n",
      "   Training Quantum Head: 8 modes, 1 photons\n",
      "   Input state: [1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Number of parameters in Quantum head: 77046\n",
      "Epoch 50/200, Train Loss: 0.5920\n",
      "Epoch 100/200, Train Loss: 0.4762\n",
      "Epoch 150/200, Train Loss: 0.3988\n",
      "Epoch 200/200, Train Loss: 0.3401\n",
      "   Quantum 8-1 - Val: 0.7960, Test: 0.7701\n",
      "\n",
      "   Training Quantum Head: 8 modes, 2 photons\n",
      "   Input state: [1, 0, 1, 0, 0, 0, 0, 0]\n",
      "Number of parameters in Quantum head: 77086\n",
      "Epoch 50/200, Train Loss: 0.6340\n",
      "Epoch 100/200, Train Loss: 0.5527\n",
      "Epoch 150/200, Train Loss: 0.4859\n",
      "Epoch 200/200, Train Loss: 0.4339\n",
      "   Quantum 8-2 - Val: 0.7360, Test: 0.6688\n",
      "\n",
      "   Training Quantum Head: 8 modes, 3 photons\n",
      "   Input state: [1, 0, 1, 0, 1, 0, 0, 0]\n",
      "Number of parameters in Quantum head: 77142\n",
      "Epoch 50/200, Train Loss: 0.6211\n",
      "Epoch 100/200, Train Loss: 0.5545\n",
      "Epoch 150/200, Train Loss: 0.4869\n",
      "Epoch 200/200, Train Loss: 0.4258\n",
      "   Quantum 8-3 - Val: 0.8240, Test: 0.7926\n",
      "\n",
      "   Training Quantum Head: 8 modes, 4 photons\n",
      "   Input state: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Number of parameters in Quantum head: 77170\n",
      "Epoch 50/200, Train Loss: 0.6411\n",
      "Epoch 100/200, Train Loss: 0.5761\n",
      "Epoch 150/200, Train Loss: 0.5137\n",
      "Epoch 200/200, Train Loss: 0.4530\n",
      "   Quantum 8-4 - Val: 0.8160, Test: 0.7797\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. Training Quantum Layer heads...\")\n",
    "modes_to_test = [ 2, 4, 6, 8]\n",
    "quantum_results = {}\n",
    "\n",
    "for mode in modes_to_test:\n",
    "    photon_max = int(mode // 2)\n",
    "\n",
    "    for k in range(1, photon_max + 1):\n",
    "        # Create input state with k photons\n",
    "        input_state = [0] * mode\n",
    "        for p in range(k):\n",
    "            input_state[2 * p] = 1\n",
    "\n",
    "        print(f\"\\n   Training Quantum Head: {mode} modes, {k} photons\")\n",
    "        print(f\"   Input state: {input_state}\")\n",
    "\n",
    "        # Create quantum model\n",
    "        model = create_setfit_with_q_layer(\n",
    "            model,\n",
    "            input_dim=768,\n",
    "            hidden_dim=100,\n",
    "            modes=mode,\n",
    "            num_classes=num_classes,\n",
    "            epochs=HEAD_EPOCHS,\n",
    "            input_state=input_state\n",
    "        )\n",
    "\n",
    "        # Train the quantum head\n",
    "        model.model_head.fit(train_embeddings, train_labels)\n",
    "\n",
    "        # Evaluate\n",
    "        q_val_predictions = model.model_head.predict(\n",
    "            sentence_transformer.encode(eval_dataset[\"sentence\"], convert_to_tensor=True).cpu().numpy()\n",
    "        )\n",
    "        q_val_accuracy = accuracy_score(eval_dataset[\"label\"], q_val_predictions)\n",
    "\n",
    "        q_test_predictions = model.model_head.predict(\n",
    "            sentence_transformer.encode(test_dataset[\"sentence\"], convert_to_tensor=True).cpu().numpy()\n",
    "        )\n",
    "        q_test_accuracy = accuracy_score(test_dataset[\"label\"], q_test_predictions)\n",
    "\n",
    "        print(f\"   Quantum {mode}-{k} - Val: {q_val_accuracy:.4f}, Test: {q_test_accuracy:.4f}\")\n",
    "        quantum_results[f\"{mode}-qlayer-{input_state}\"] = [q_val_accuracy, q_test_accuracy]\n",
    "\n",
    "results[\"Qlayer\"] = quantum_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:47:22.163959300Z",
     "start_time": "2025-06-05T14:40:05.432499500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 9. Results Summary and Visualization\n",
    "\n",
    " Let's visualize and analyze the results from all classification heads.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTS SUMMARY ===\n",
      "\n",
      "Classical Methods:\n",
      "LogisticRegression   - Val: 0.7680, Test: 0.7235\n",
      "SVC                  - Val: 0.7600, Test: 0.7395\n",
      "MLP                  - Val: 0.8120, Test: 0.7797\n",
      "\n",
      "Quantum Methods (best per mode count):\n",
      "2 modes              - Val: 0.5160, Test: 0.5064\n",
      "4 modes              - Val: 0.7920, Test: 0.7685\n",
      "6 modes              - Val: 0.8040, Test: 0.7669\n",
      "8 modes              - Val: 0.8240, Test: 0.7926\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Extract results for visualization\n",
    "classical_methods = ['LogisticRegression', 'SVC', 'MLP']\n",
    "classical_val_accs = [results[method][0] for method in classical_methods]\n",
    "classical_test_accs = [results[method][1] for method in classical_methods]\n",
    "\n",
    "# Process quantum results\n",
    "quantum_configs = list(results['Qlayer'].keys())\n",
    "quantum_val_accs = [results['Qlayer'][config][0] for config in quantum_configs]\n",
    "quantum_test_accs = [results['Qlayer'][config][1] for config in quantum_configs]\n",
    "\n",
    "# Create comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Validation accuracies\n",
    "x_classical = range(len(classical_methods))\n",
    "x_quantum = range(len(classical_methods), len(classical_methods) + len(quantum_configs))\n",
    "\n",
    "ax1.bar(x_classical, classical_val_accs, color='skyblue', label='Classical')\n",
    "ax1.bar(x_quantum, quantum_val_accs, color='lightcoral', label='Quantum')\n",
    "ax1.set_xticks(list(x_classical) + list(x_quantum))\n",
    "ax1.set_xticklabels(classical_methods + [c.split('-')[0] + 'm' for c in quantum_configs], rotation=45, ha='right')\n",
    "ax1.set_ylabel('Validation Accuracy')\n",
    "ax1.set_title('Validation Performance Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Test accuracies\n",
    "ax2.bar(x_classical, classical_test_accs, color='skyblue', label='Classical')\n",
    "ax2.bar(x_quantum, quantum_test_accs, color='lightcoral', label='Quantum')\n",
    "ax2.set_xticks(list(x_classical) + list(x_quantum))\n",
    "ax2.set_xticklabels(classical_methods + [c.split('-')[0] + 'm' for c in quantum_configs], rotation=45, ha='right')\n",
    "ax2.set_ylabel('Test Accuracy')\n",
    "ax2.set_title('Test Performance Comparison')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "print(\"\\nClassical Methods:\")\n",
    "for i, method in enumerate(classical_methods):\n",
    "    print(f\"{method:20s} - Val: {classical_val_accs[i]:.4f}, Test: {classical_test_accs[i]:.4f}\")\n",
    "\n",
    "print(\"\\nQuantum Methods (best per mode count):\")\n",
    "modes_processed = set()\n",
    "for config in quantum_configs:\n",
    "    mode_count = config.split('-')[0]\n",
    "    if mode_count not in modes_processed:\n",
    "        # Find best accuracy for this mode count\n",
    "        mode_configs = [c for c in quantum_configs if c.startswith(mode_count + '-')]\n",
    "        best_val = max(results['Qlayer'][c][0] for c in mode_configs)\n",
    "        best_test = max(results['Qlayer'][c][1] for c in mode_configs)\n",
    "        print(f\"{mode_count + ' modes':20s} - Val: {best_val:.4f}, Test: {best_test:.4f}\")\n",
    "        modes_processed.add(mode_count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:47:22.663205600Z",
     "start_time": "2025-06-05T14:47:22.172684Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ### 9.1 Save Results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved. Total experiments: 3\n",
      "\n",
      "Experiment completed successfully!\n",
      "Results saved to ./results/quantum_llm_finetuning_results.json\n"
     ]
    }
   ],
   "source": [
    "save_experiment_results(results, \"quantum_llm_finetuning_results.json\")\n",
    "\n",
    "print(\"\\nExperiment completed successfully!\")\n",
    "print(f\"Results saved to ./results/quantum_llm_finetuning_results.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:47:22.672706400Z",
     "start_time": "2025-06-05T14:47:22.663205600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    " ## 10. Analysis and Conclusions\n",
    "\n",
    " Based on the experimental results, we can draw several insights:\n",
    "\n",
    " ### Performance Comparison\n",
    "\n",
    " 1. **Classical Baselines**:\n",
    "    - Logistic Regression provides a strong baseline despite its simplicity\n",
    "    - SVM often performs competitively in few-shot scenarios\n",
    "    - MLP can capture non-linear patterns but may overfit with limited data\n",
    "\n",
    " 2. **Quantum Classifiers**:\n",
    "    - Performance varies with the number of modes and photons\n",
    "    - Smaller quantum circuits (2-4 modes) often perform comparably to classical methods\n",
    "    - Larger circuits may suffer from optimization challenges\n",
    "\n",
    " ### Key Observations\n",
    "\n",
    " - **Few-shot learning**: With only 8 samples per class, simpler models often generalize better\n",
    " - **Quantum advantage**: Quantum models show promise but require careful hyperparameter tuning\n",
    " - **Computational trade-offs**: Quantum simulations are computationally intensive compared to classical methods\n",
    "\n",
    " ### Future Directions\n",
    "\n",
    " 1. **Scaling studies**: Test with more training samples to see if quantum models benefit from larger datasets\n",
    " 2. **Architecture exploration**: Try different quantum circuit designs and encoding strategies\n",
    " 3. **Hardware implementation**: Evaluate on real quantum photonic hardware when available\n",
    " 4. **Hybrid approaches**: Combine classical and quantum layers for potentially better performance\n",
    "\n",
    " The results demonstrate that quantum photonic classifiers can achieve competitive performance in NLP tasks, opening new avenues for quantum-enhanced machine learning in language processing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
